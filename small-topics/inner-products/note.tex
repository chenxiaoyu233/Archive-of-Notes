\documentclass{article}
\usepackage{geometry}
\geometry{a4paper, scale = 0.8}

\usepackage{ctex}
\usepackage{amsmath, amssymb, amsthm}
\everymath{\displaystyle}
\newtheorem{define}{Define}
\newtheorem{fact}{Fact}
\newtheorem{property}{Property}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{remark}{Remark}
\newtheorem{proposition}{Proposition}

\usepackage{tabularx}

\title{Some Notes For Inner Products}
\author{Xiaoyu Chen}
\date{}

% 简化书写
\def\<{\langle}
\def\>{\rangle}

\begin{document}
\maketitle
\begin{define}[Inner Products]
  对于一个定义在域$\mathbb{F}$($\mathbb{F}$ 可以是 $\mathbb{R}, \mathbb{C}$)上的向量空间$V$. 如果函数 $\< \cdot, \cdot \>: V\times V \to \mathbb{F}$ 对于 $\forall x, y, z\in V$ 和 $\forall c\in \mathbb{F}$ 都满足:

  \begin{tabularx}{0.9\textwidth}{llXr}
    (1) & $\< x, x \> \geq 0$ && 非负性 (Nonnegativity) \\
    (1a) & $\< x, x \> = 0$ iff $x = 0$ && 正性 (Positivity) \\
    (2) & $\< x + y, z \> = \< x, z \> + \< y, z \>$ && 可加性 (Additivity) \\
    (3) & $\< cx, y \> = c\< x, y \>$ && 齐次性 (Homogeneity) \\
    (4) & $\< x , y \> = \overline{\< y, x \>}$ && 共轭对称性 (Hermitian Property) \\
  \end{tabularx}

  $\Rightarrow$ 则$\< \cdot, \cdot \>$ 是一个\textbf{内积} (inner product). 
  
  $\Rightarrow$ 如果不考虑(1a), 我们称 $\<\cdot, \cdot\>$ 是一个\textbf{半内积} (semi-inner product). 所以内积当然也是半内积.

  $\triangle$ 上面这些性质有些时候也被称为内积的\textbf{公理}.
\end{define}

\begin{fact}
  $\< x, y \> := y^*x$ 是一个内积
\end{fact}

\begin{fact}
  对于函数 $(\cdot, \cdot): V\times V \to \mathbb{F}$.
  $(x, y) := y^*Dx$, 其中 $D = \mathrm{diag}(d_1, \cdots, d_n) \in M_n(\mathbb{F})$, 有:

  \begin{tabular}{l@{ $\Leftarrow$ }l}
    (1) & 如果$D$满足$d_i \geq 0, \forall i\in [n]$ \\
    (1a) & 如果$D$满足$d_i > 0, \forall i \in [n]$ \\
    (2) & $\forall D$ \\
    (3) & $\forall D$ \\
    (4) & $D = D^*$, i.e. $D$ 是 Hermitian 阵
  \end{tabular}

  特别的, 如果 $D$ 实对角阵, 且对角元全部 $> 0$, 则 $(\cdot, \cdot)$ 是一个内积.
\end{fact}

\begin{property}
通过内积的定义, 可以导出如下性质:

\begin{tabular}{ll}
  (a) & $\< x, cy \> = \overline{c}\< x, y\>$ \\
  (b) & $\< x, y + z \> = \< x, y \> + \< x, z \>$ \\
  (c) & $\< ax + by, cw + dz \> = a\overline{c}\<x, w\> + a\overline{d}\<x, z\> + b\overline{c}\<y, w\> + b\overline{d}\<y, z\>$ \\
  (d) & $\< x, \<x, y\>y\> = \<x, y\>\overline{\< x, y\>} = |\<x, y\>|^2$ \\
  (e) & $\<x, y\> = 0, \forall y \in V$ iff $x = 0$
\end{tabular}

这里只有(e)的证明需要用到(1)和(1a).
\end{property}

\begin{theorem}[Cauchy–Schwarz inequality]
  对于任意的半内积$\<\cdot,\cdot\>: V\times V\to \mathbb{F}$, 我们都有:
  \[|\<x, y\>|^2 \leq \<x, x\>\<y, y\>, \hspace{0.5cm} \forall x, y\in V\]
\end{theorem}
\begin{proof}[proof.(半内积).]
  考虑一个多项式$p(t) = \<tx - e^{i\theta}y, tx - e^{i\theta}y\>, \forall t, \theta\in\mathbb{R}, x, y\in V$, 这时有:
  \begin{align*}
    p(t) &= (tx - e^{i\theta}y)^*(tx - e^{i\theta}y) \\
         &= (tx^* - e^{-i\theta}y^*)(tx - e^{i\theta}y) \\
         &= t^2\<x, x\> - te^{i\theta}\<y, x\> - te^{-i\theta}\<x, y\> + \<y,y\> \\
         &= t^2\<x,x\> - \overline{te^{-i\theta}\<x, y\>}  - te^{-i\theta}\<x, y\> + \<y, y\> \\
    &= t^2\<x, x\> - 2\mathrm{Re}\left[te^{-i\theta}\<x, y\>\right] + \<y, y\>
  \end{align*}
  这个时候, 我们将 $\theta$ 取定, 使其满足 $e^{-i\theta} \<x, y\> = |\<x, y\>|$, 因为 $\<x, y\> \in \mathbb{F} \subset \mathbb{C}$, 所以这样的 $\theta$ 一定存在.
  所以, 这时我们有 $p(t) = t^2\<x,x\> - 2t|\<x, y\>| + \<y, y\>$.
  
  这个时候, 如果 $\<x, x\> = 0 \land \<x, y\> \not= 0$, 则 $p(t) = -2t|\<x, y\>| + \<y, y\>$那么当 $t$ 足够大的时候, $p(t) < 0$, 这不满足\textbf{公理(1)}.
  所以当 $\<x, x\> = 0$ 时, $\<x, y\> = 0$, $|\<x, y\>|^2 \leq \<x,x\>\<y,y\>$自然满足.

  如果 $\<x, x\> \not= 0$. 则我们可以令 $t_0 = \frac{|\<x, y\>|}{\<x,x\>}$.
  则:
  \begin{displaymath}
  \begin{array}{rl}
    p(t_0) &= \frac{|\<x,y\>|^2}{\<x,x\>} - 2\frac{|\<x,y\>|^2}{\<x,x\>} + \<y,y\> \\
           & \begin{array}{lrl}
                = & -\frac{|\<x,y\>|^2}{\<x,x\>} + \<y, y\> &\geq 0 \\
                \Rightarrow & \<y, y\> &\geq \frac{|\<x,y\>|^2}{\<x,x\>} \\
                & \<x, x\>\<y, y\> &\geq |\<x, y\>|^2 
              \end{array} 
  \end{array}
\end{displaymath}
\end{proof}
上面这个证明对于内积和半内积都是有效的.
不过, 如果只关注内积, 还有一个更加简单的证明方法.
\begin{proof}[proof.(内积).]
  考虑 $v = \<y, y\>x - \<x, y\> y$. 则
  \begin{align*}
    0 &\leq \<v,v\> \\
      &= \<\<y, y\>x - \<x, y\> y, \<y, y\>x - \<x, y\> y\> \\
      &= \<y,y\>^2\<x,x\> - \<y,y\>\overline{\<x,y\>}\<x,y\> \underbrace{-\<x,y\>\<y,y\>\<y,x\> + \<x,y\>\overline{\<x,y\>}\<y,y\>}_{0} \\
      &= \<y,y\>^2\<x,x\> - \<y,y\>\overline{\<x,y\>}\<x,y\> \\
    &= \<y, y\> (\<y, y\>\<x, x\> - \overline{\<x, y\>}\<x, y\>)
  \end{align*}
  
  如果 $\<y, y\> = 0$, 则 $y = 0$, 则 $\<x, y\> = 0$, 结论显然成立.

  另一方面, 如果 $\<y, y\> \not= 0$, 则我们知道:
  \begin{align*}
    0 \leq \<y, y\>\<x, x\> - \overline{\<x, y\>}\<x, y\> \\
    |\<x, y\>|^2 \leq \<x,x\>\<y,y\>
  \end{align*}
  这种证明方式还告诉我们, \textbf{考虑内积时}, 柯西不等式取等的条件是:
  \begin{align*}
    v &= 0 \\
    \<y,y\>x &= \<x, y\>y \\
    x &= \frac{\<x, y\>}{\<y,y\>}y
  \end{align*}
  即 $x$ 和 $y$ 线性相关 (平行).
\end{proof}
\begin{define}[范数(norm)]
  令 $V$ 是 $\mathbb{F}$ ($\mathbb{R}$ 或 $\mathbb{C}$) 上的一个向量空间.
  一个函数 $||\cdot||: V\to \mathbb{F}$ 如果对于 $\forall x, y\in V, \forall c\in \mathbb{F}$ 满足:
  
  \begin{tabularx}{0.9\textwidth}{llXr}
    (1) & $||x|| > 0$ && 非负性 (Nonnegativity) \\
    (1a) & $||x|| = 0$ iff $x = 0$ && 正性 (Positivity) \\
    (2) & $||cx|| = c||x||$ && 齐次性 (Homogeneity) \\
    (3) & $||x + y || \leq ||x|| + ||y||$ && 三角形不等式 (Triangle Inequality)
  \end{tabularx}

  $\Rightarrow$ 则称 $||\cdot||$ 是一个\textbf{范数}(norm).
  
  $\Rightarrow$ 如果 不考虑 (1a), 则称 $||\cdot||$ 是一个 \textbf{半范数} (semi-norm).
\end{define}
\begin{lemma}
  $||\cdot||$ 是一个在 $\mathbb{F}$ 上的半范数, 则 
  \[|\,||x|| - ||y||\,| \leq ||x - y||\]
\end{lemma}
\begin{proof}[proof]
  因为 $x = y + (x  - y)$ 所以根据三角形不等式, 有
  \begin{align*}
    ||x|| &\leq ||y|| + ||x - y|| \\
    ||x|| - ||y|| &\leq ||x - y||
  \end{align*}
  同理, 可以得到 $||y|| - ||x|| \leq ||x - y||$.
\end{proof}

\begin{fact}
  如果有一个(半)内积$\<\cdot, \cdot\>: V\times V\to\mathbb{F}$, 则我们可以通过$||x||:= \<x,x\>^{1/2}$ 来定义出一个(半)范数.
\end{fact}
\begin{proof}
  (1), (1a), (2) 都很好验证, 下面来说明如何验证 (3).
  \begin{align*}
    ||x + y||^2 &= \<x + y, x + y\> \\
                &= \<x, x\> + \<x, y\> + \<y, x\> + \<y, y\> \\
                &= ||x||^2 + ||y||^2 + \<x, y\> + \<y, x\> \\
                &= ||x||^2 + ||y||^2 + 2\mathrm{Re}\left[\<x, y\>\right] \\
                &\leq ||x||^2 + ||y||^2 + 2|\<x, y\>| \\
                &\leq ||x||^2 + ||y||^2 + 2\<x,x\>^{1/2}\<y,y\>^{1/2} \\
                &= ||x||^2 + ||y||^2 + 2||x||\,||y|| \\
                &= (||x|| + ||y||)^2 \qedhere
  \end{align*}
\end{proof}

\section{Self-Adjoint Operator}
\begin{define}[adjoint]
  Let $V$ and $W$ be real or complex finite dimensional vector spaces with inner
  products $\<\cdot,\cdot\>_V$ and $\<\cdot,\cdot\>_W$, respectively.
  Let $L: V\to W$ be linear. If there is a transformation $L^*:W\to V$ for which
  \begin{equation}
    \<Lv, w\>_W = \<v, L^*w\>_V\label{eq:def-adjoint}
  \end{equation}
  holds for every pair of vectors $v\in V$ and $w\in W$, then $L^*$ is said to be the \emph{adjoint} of $L$.
\end{define}
\begin{remark}
  这里, $v\in V, L:V\to W$, 所以 $Lv\in W$, 所以 $\<Lv, w\>_W$ 中 左右两个变量都在 $W$  中.
  同理, $w\in W, L^*:W\to V$, 所以 $L^*w\in V$, 所以 $\<v, L^*w>_V$ 中,  左右两个变量都在 $V$ 中.
\end{remark}

在下面的证明中, 我们会用到关于向量和矩阵表示的问题, 这里需要引入基变换的语言.
\begin{define}[Change of Basis]
  $V$ 中一组相互正交的单位向量 $\mathcal{B} = \{v_1, v_2, \cdots, v_n\}$ 可以作为 $V$ 这个空间的一组基.
  对于 $\forall x\in V$, 我们可以通过 $\mathcal{B}$ 来表示出 $x$.
  如果 $x = \alpha_1v_1 + \alpha_2v_2 + \cdots + \alpha_nv_n$, 则
  \[[x]_{\mathcal{B}} = \left[
      \begin{array}{c}
        \alpha_1 \\
        \alpha_2 \\
        \vdots \\
        \alpha_n
      \end{array}
    \right]\]
  称为 $x$ 在 基 $\mathcal{B}$ 中的表示 ($\mathcal{B}$ basis representation of $x$).
\end{define}

仅仅有向量的基表示是不够的,矩阵同样需要有基表示.
假设现在有两个基 $\mathcal{B}_1, \mathcal{B}_2$, 对于任何一个向量 $x\in V$,
我们希望写出 $Tx$ 在 $\mathcal{B}_2$ 中的表示 $[Tx]_{\mathcal{B}_2}$.
不妨 $\mathcal{B}_1 = \{v_1, v_2, \cdots, v_n\}$, 且
\[[x]_{\mathcal{B}_1} = \left[
    \begin{array}{c}
      \alpha_1 \\
      \alpha_2 \\
      \vdots \\
      \alpha_n
    \end{array}
  \right]\]
那么我们有
\begin{align*}
  [Tx]_{\mathcal{B}_2} &= \left[\sum_{j=1}^n \alpha_jTv_j\right]_{\mathcal{B}_2} = \sum_{j=1}^n \alpha_j[Tv_j]_{\mathcal{B}_2}\\
    &= \sum_{j=1}^n \alpha_j \left[
        \begin{array}{c}
        t_{1j}\\
        \vdots \\
        t_{nj}
        \end{array}
  \right] = \left[
  \begin{array}{ccc}
    t_{11}&\cdots& t_{1n} \\
    \vdots & \ddots & \vdots \\
    t_{n1} & \cdots & t_{nn}
  \end{array}
  \right]\left[
    \begin{array}{c}
      \alpha_1 \\
      \vdots \\
      \alpha_n
    \end{array}
  \right]
\end{align*}
所以, 可以做如下定义

\begin{define}
\[ _{\mathcal{B}_2}[T]_{\mathcal{B}_1} = 
  \left[
  \begin{array}{ccc}
    t_{11}&\cdots& t_{1n} \\
    \vdots & \ddots & \vdots \\
    t_{n1} & \cdots & t_{nn}
  \end{array}
\right] =
[[Tv_1]_{\mathcal{B}_2}, \cdots, [Tv_n]_{\mathcal{B}_2}]
\]
这是因为从上面的观察可以发现 $_{\mathcal{B}_2}[T]_{\mathcal{B}_1}[x]_{\mathcal{B}_1} = [Tx]_{\mathcal{B}_2}$.
所以 $_{\mathcal{B}_1}[T]_{\mathcal{B}_2}$ 的取值情况和 $x$ 无关.
特别的, 当 $\mathcal{B}_1 = \mathcal{B}_2$ 时, 我们称这种形式$_{\mathcal{B}_1}[T]_{\mathcal{B}_1}$为 $T$ 在基 $\mathcal{B}_1$ 中的表示 ($\mathcal{B}_1$ basis representation of $T$).
\end{define}

\begin{fact}
  基变换, 不改变矩阵的特征值.
  i.e. $Av = \lambda v \Leftrightarrow _{\mathcal{B}}[A]_{\mathcal{B}}[v]_{\mathcal{B}} = \lambda [v]_{\mathcal{B}}$.
\end{fact}
\begin{proof}
  $\Rightarrow$:\\
  \begin{align*}
    _{\mathcal{B}}[A]_{\mathcal{B}}[v]_{\mathcal{B}} &= [Av]_{\mathcal{B}} \\
    &= [\lambda v]_{\mathcal{B}} = \lambda [v]_{\mathcal{B}}
  \end{align*}

  $\Leftarrow$:\\
  \begin{align*}
    [Av]_{\mathcal{B}} &= _{\mathcal{B}}[A]_{\mathcal{B}}[v]_{\mathcal{B}} \\
    &= \lambda [v]_{\mathcal{B}} \\
    &= [\lambda v]_{\mathcal{B}}
  \end{align*}
  所以 $Av = \lambda v$ (因为 $Av$ 和 $\lambda v$ 在 基 $\mathcal{B}$ 下是同一种表示).
\end{proof}

\begin{define}[self-adjoint]
  对于任意一个inner product $\<\cdot, \cdot\>_V$, 和矩阵 $L: V\to V$.
  如果对任意 $x, y\in V$, 都有:
  \[\<Lx, y\>_V = \<x, Ly\>_V\]
  (i.e. $L = L^*$), 则我们说 $L$ 是 self-adjoint 的.
\end{define}
self-adjoint 的矩阵的特征向量有很有用的性质.
\subsection{Properties for self-adjoint operator}
\begin{remark}
  这一小节中, 我么讨论的内积 $\<\cdot, \cdot\>$ 都是一般的内积.
\end{remark}
\begin{proposition}
  Let $V$ be a complex vector space with an inner product.
  If $L: V\to V$ is a self-adjoint linear transformation,
  then the eigenvalues of $L$ are real numbers, and eigenvectors of $L$ corresponding to distinct eigenvalues are orthogonal.
\end{proposition}
\begin{proof}
  \emph{[1] the eigenvalues of $L$ are all real numbers}:\\
  如果 $L$ 有一个特征值对 $(\lambda, v)$ (不妨 $\<v, v\> = 1$), 则我们有:
  \[\lambda = \lambda\<v, v\> = \<\lambda v, v\> = \<Lv, v\> = \<v, Lv\> = \<v,\lambda v\> = \overline{\lambda}\<v, v\> = \overline{\lambda}\]
  所以很容易可以看出来, $\lambda$ 应该是一个实数.

  \emph{[2] the eigenvectors of $L$ corresponding to distinct eigenvalues are orthogonal}: \\
  考虑 $L$ 的两个不同的特征值对 $(\lambda_1, v_1)$, $(\lambda_2, v_2)$, 且 $\lambda_1 \not= \lambda_2$ (注意, 这里由[1]可知, $\lambda_1, \lambda_2\in\mathbb{R}$).
  然后就有
  \[\lambda_1\<v_1, v_2\> = \<\lambda_1v_1, v_2\> = \<Lv_1, v_2\> = \<v_1, Lv_2\> = \<v_1,\lambda_2v_2\> = \overline{\lambda_2}\<v_1, v_2\> = \lambda_2\<v_1, v_2\>\]
  容易看出, 因为 $\lambda_1 \not= \lambda_2$, 所以这个式子只在 $\<v_1, v_2\> = 0$ 时成立.
\end{proof}

\begin{fact}
  If we do not change the definition of matrix multiplication.
  Then, for two different inner products $\<\cdot, \cdot\>_a, \<\cdot, \cdot\>_b$, defined on the same n-dimensional space $V$,
  $\forall A\in V\to V$ which is linear, $A$ has the same eigenvalues on both inner-spaces.
\end{fact}
\begin{proof}
  要理解这个Fact, 只需要回顾eigenvalue的定义, 通常我们使用下面的方式来定义$A$的eigenvalues:
  \[\{\lambda | v\in V, Av = \lambda v\}\]
  所以, 很容易能看出, inner product 的定义对 $A$ 的特征值的取值是不会产生影响的.
\end{proof}

\begin{lemma}
  Let $V$ be a complex, finite dimensional vector space with dimension $\geq 1$,
  if $L: V\to V$ is linear, then $L$ has at least one eigenvalue.
\end{lemma}
\begin{proof}
  由上面的Fact可知, 我们在考虑矩阵的特征值时不需要考虑inner product的定义.
  而方程 $\mathrm{det}(A - \lambda I) = 0$ 一定会有 $1\sim n$ 个不同的界.
  所以矩阵 $L$ 当然会有至少一个特征值 (这个特征值当然也有对应的特征向量).
\end{proof}
\begin{remark}
  上面的证明只说明了 $L$ 是一个 在 $V\to V$ 上转移的矩阵的情况, 下面我们来证明一个
  更加强的结论.
\end{remark}
\begin{lemma}
  Let $G$ be a complex, finite dimensional vector space with dimension $\geq 1$.
  If $L:G\to G$ is a linear transformation on $G$.
  Then, for a subspace $V$ of $G$, if $L|_V: V\to V$ (i.e. $L$ is closed on $V$),
  then $L|_V$ has at least one eigenvalue on $V$.
\end{lemma}
\begin{proof}
  不妨 $G$ 是一个 $n$ 维空间,  $V$ 是 $G$ 的一个子空间, 有 $m$ 维.
  $V^\perp$ 当然也是$G$ 的一个子空间, 有 $n - m$ 维.

  这个时候, 我们可以从 $V$ 中选出 $m$ 个正交的单位向量 $\{v_1, v_2, \cdots, v_m\}$.
  同样, 我们可以从 $V^\perp$ 中选出 $n-m$ 个正交的单位向量 $\{v_1^\perp, v_2^\perp, \cdots, v_{n-m}^\perp\}$. 显然, 将这些向量放到一起, 我们就得到了 $G$ 的一组基:
  \[\mathcal{B} = \{v_1, v_2, \cdots, v_m, v_1^\perp, v_2^\perp, \cdots, v_{n-m}^\perp\}\]
  所以, $\forall x\in V$, 有:
  \begin{align*}
    _{\mathcal{B}}[L]_{\mathcal{B}}[x]_{\mathcal{B}}
    &= [[Lv_1]_{\mathcal{B}}, [Lv_2]_{\mathcal{B}}, \cdots, [Lv_m]_{\mathcal{B}}, [Lv_1^\perp]_{\mathcal{B}}, \cdots [Lv_{n-m}^\perp]_{\mathcal{B}}][x]_{\mathcal{B}} \\
    &= \left[
      \begin{array}{cc}
        A_{m\times m}& \bigstar_{m\times n-m} \\
        0_{n-m\times m} & \bigstar_{n-m\times n-m}
      \end{array}
      \right] \left[
        \begin{array}{c}
          x_m \\
          0_{n-m}
        \end{array}
    \right] \\
    &= \left[
      \begin{array}{c}
        A_{m\times m} x_m \\
        0_{n-m}
      \end{array}
      \right]
    \end{align*}
    结合前面基变换不改变特征值的结论, 可以知道对于 $x \in V$,
    $L$  的特征值, 等于 $A_{m\times m}$ 的特征值 ($A$ 有的特征值 $L$ 都有).
    在由前面一个Lemma给出的结论, 可以知道, $L$ 在 $V$ 上至少有一个特征值.
\end{proof}
\begin{remark}
  上面两个Lemma联合起来, 就证明了一般的情况.
  即, 如果 $L: V\to V$, 这里只是说 $L$ 在 $V$ 这个空间封闭, 则 $L$ 一定在这个空间至少有一个特征值(当然也就有至少一个特征向量).
\end{remark}
下面给出self-adjoint operator的一个非常重要的性质.
\begin{theorem}
  Let $V$ be a complex, finite dimensional vector space.
  If $L: V\to V$ is a self-adjoint linear transformation, then thre is an orthonormal basis for $V$ that is composed of eigenvectors of $L$.
  The matrix of $L$ related to this basis is diagonal.
\end{theorem}
\begin{remark}
  用人话说就是: 任意一个内积的self-adjoint operator的特征向量都可以构成关于这个内积的一组基.
\end{remark}
\begin{proof}
  显然, $L$ 的所有特征向量, 一定可以构成一个子空间的正交基, 计作 $\mathcal{B}$.
  我们将 $L$ 的所有特征向量张成的空间 记为 $B = \mathrm{Span}(\mathcal{B})$, 然后 $S = B^\perp$.
  不难发现, $L$ 对 $S$ 是封闭的, 对于$\forall v\in \mathcal{B}, u\in S$.
  \[\<v, Lu\> = \<Lv, u\> = \<\lambda v, u\> = \lambda\<v, u\> = 0\]
  所以 $Lu$ 和 $v$ 依然关于 $\<\cdot, \cdot\>$ 正交.
  因为这对于所有的特征向量都成立, 所以有 $Lu \perp B$, 也就是说  $Lu \in S$.
  所以, 我们可以说, $S$ 关于 $L$ 是封闭的.

  然后利用我们前面的结论可以看出, 如果 $S \not=\{0\}$, 则 $L$ 在 $S$ 中一定存在一个特征值, 也就存在一个特征向量. 但是这样的话, 这个特征向量就也应该存在于 $B$ (根据定义). 这导致 $B \cap S \not = \emptyset$, 就产生了矛盾.

  所以我们一定有 $S = \{0\}$.
  所以 $L$ 的所有特征向量一定可以关于 $\<\cdot, \cdot\>$ 构成一个 $V$ 的基.
\end{proof}
\begin{remark}
  这个定理, 会导致本来只在一般inner product上成立的Courant-Fischer Theorem]在任意self-adjoint上成立.
\end{remark}
\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
